{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de árboles de decisión y métodos de ensamblaje\n",
    "\n",
    "En este taller podrá poner en práctica los sus conocimientos sobre construcción e implementación de árboles de decisión y métodos de ensamblajes. El taller está constituido por 9 puntos, 5 relacionados con árboles de decisión (parte A) y 4 con métodos de ensamblaje (parte B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte A - Árboles de decisión\n",
    "\n",
    "En esta parte del taller se usará el conjunto de datos de Capital Bikeshare de Kaggle, donde cada observación representa el alquiler de bicicletas durante una hora y día determinado. Para más detalles puede visitar los siguientes enlaces: [datos](https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip), [dicccionario de datos](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos prestamo de bicicletas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>total</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season  holiday  workingday  weather  temp   atemp  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "                     humidity  windspeed  casual  registered  total  hour  \n",
       "datetime                                                                   \n",
       "2011-01-01 00:00:00        81        0.0       3          13     16     0  \n",
       "2011-01-01 01:00:00        80        0.0       8          32     40     1  \n",
       "2011-01-01 02:00:00        80        0.0       5          27     32     2  \n",
       "2011-01-01 03:00:00        75        0.0       3          10     13     3  \n",
       "2011-01-01 04:00:00        75        0.0       0           1      1     4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "bikes = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/bikeshare.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# Renombrar variable \"count\" a \"total\"\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Crear la hora como una variable \n",
    "bikes['hour'] = bikes.index.hour\n",
    "\n",
    "# Visualización de los datos\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Análisis descriptivo\n",
    "\n",
    "Ejecute las celdas 1.1 y 1.2. A partir de los resultados realice un análisis descriptivo sobre las variables \"season\" y \"hour\", escriba sus inferencias sobre los datos. Para complementar su análisis puede usar métricas como máximo, mínimo, percentiles entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "1    116.343261\n",
       "2    215.251372\n",
       "3    234.417124\n",
       "4    198.988296\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.1\n",
    "bikes.groupby('season').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0      55.138462\n",
       "1      33.859031\n",
       "2      22.899554\n",
       "3      11.757506\n",
       "4       6.407240\n",
       "5      19.767699\n",
       "6      76.259341\n",
       "7     213.116484\n",
       "8     362.769231\n",
       "9     221.780220\n",
       "10    175.092308\n",
       "11    210.674725\n",
       "12    256.508772\n",
       "13    257.787281\n",
       "14    243.442982\n",
       "15    254.298246\n",
       "16    316.372807\n",
       "17    468.765351\n",
       "18    430.859649\n",
       "19    315.278509\n",
       "20    228.517544\n",
       "21    173.370614\n",
       "22    133.576754\n",
       "23     89.508772\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.2\n",
    "bikes.groupby('hour').total.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Análisis de gráficos\n",
    "\n",
    "Primero ejecute la celda 2.1 y asegúrese de comprender el código y el resultado. Luego, en cada una de celdas 2.2 y 2.3 escriba un código que genere una gráfica del número de bicicletas rentadas promedio para cada valor de la variable \"hour\" (hora) cuando la variable \"season\" es igual a 1 (invierno) e igual a 3 (verano), respectivamente. Analice y escriba sus hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b44eaa72e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.1 - rentas promedio para cada valor de la variable \"hour\"\n",
    "bikes.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b44ebaba00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.2 - \"season\"=1 escriba su código y hallazgos \n",
    "bikes.query('season==1').groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b450ca8610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.3 - \"season\"=3 escriba su código y hallazgos \n",
    "bikes.query('season==3').groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Regresión lineal\n",
    "En la celda 3 ajuste un modelo de regresión lineal a todo el conjunto de datos, utilizando \"total\" como variable de respuesta y \"season\" y \"hour\" como las únicas variables predictoras, teniendo en cuenta que la variable \"season\" es categórica. Luego, imprima los coeficientes e interprételos. ¿Cuáles son las limitaciones de la regresión lineal en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 10.54520609, 100.31723192, 119.46754995,  84.08311787]),\n",
       " -6.430262462306814)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3\n",
    "\n",
    "X=bikes[[\"season\",\"hour\"]]\n",
    "y=bikes[\"total\"]\n",
    "X_dummies=pd.get_dummies(bikes['season'], prefix='season', drop_first=True)\n",
    "\n",
    "X = pd.concat([X, X_dummies], axis=1)\n",
    "X.drop('season', axis=1, inplace=True)\n",
    "\n",
    "reg=LinearRegression()\n",
    "reg.fit(X,y)\n",
    "\n",
    "(reg.coef_,reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  25592.233069213853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 10.727042  ,  99.75849224, 115.07834048,  88.91820601]),\n",
       " -8.187223101039052)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividir la muestra en entrenamiento y validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "reg=LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Calcular el MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "(reg.coef_,reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Árbol de decisión manual\n",
    "En la celda 4 cree un árbol de decisiones para pronosticar la variable \"total\" iterando **manualmente** sobre las variables \"hour\" y  \"season\". El árbol debe tener al menos 6 nodos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4\n",
    "# Definición de parámetros y criterios de parada\n",
    "max_depth = 6\n",
    "num_pct = 10\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función que calcula el MSE\n",
    "def mse(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean((y - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_reduction(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    mse_y = mse(y)\n",
    "    mse_l = mse(y_l)\n",
    "    mse_r = mse(y_r)\n",
    "    \n",
    "    mse_reduction_ = mse_y - (n_l / (n_l + n_r) * mse_l + n_r / (n_l + n_r) * mse_r)\n",
    "      \n",
    "    return mse_reduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función best_split para calcular cuál es la mejor variable y punto de corte para hacer la bifurcación del árbol\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, reduction\n",
    "    \n",
    "    # Para todas las variables \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            reduction = mse_reduction(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if reduction > best_split[2]:\n",
    "                best_split = [j, split, reduction]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = y.mean()\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_predict para hacer predicciones según las variables 'X' y el árbol 'tree'\n",
    "\n",
    "def tree_predict(X, tree):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        predicted = tree['y_pred']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'])\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'])\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'])\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'])\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 191.37034120734907,\n",
       " 'level': 0,\n",
       " 'split': [0, 8.0],\n",
       " 'n_samples': 7620,\n",
       " 'gain': 9407.867165488675,\n",
       " 'sl': {'y_pred': 54.60392156862745,\n",
       "  'level': 1,\n",
       "  'split': [0, 7.0],\n",
       "  'n_samples': 2550,\n",
       "  'gain': 3490.6324913574053,\n",
       "  'sl': {'y_pred': 32.54423592493298,\n",
       "   'level': 2,\n",
       "   'split': [0, 6.0],\n",
       "   'n_samples': 2238,\n",
       "   'gain': 345.63134682338796,\n",
       "   'sl': {'y_pred': 24.950469238790408,\n",
       "    'level': 3,\n",
       "    'split': [0, 1.0],\n",
       "    'n_samples': 1918,\n",
       "    'gain': 168.69183262594936,\n",
       "    'sl': {'y_pred': 53.599388379204896,\n",
       "     'level': 4,\n",
       "     'split': [2, 1.0],\n",
       "     'n_samples': 327,\n",
       "     'gain': 158.0383259038456,\n",
       "     'sl': {'y_pred': 46.326530612244895,\n",
       "      'level': 5,\n",
       "      'split': [3, 1.0],\n",
       "      'n_samples': 245,\n",
       "      'gain': 34.86522819772472,\n",
       "      'sl': {'y_pred': 42.176829268292686,\n",
       "       'level': 6,\n",
       "       'split': [1, 1.0],\n",
       "       'n_samples': 164,\n",
       "       'gain': 145.87832552255054,\n",
       "       'sl': {'y_pred': 29.950617283950617,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 81,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 54.10843373493976,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 83,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 54.72839506172839,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 81,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 75.32926829268293,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 82,\n",
       "      'gain': 0}},\n",
       "    'sr': {'y_pred': 19.062225015713388,\n",
       "     'level': 4,\n",
       "     'split': [0, 3.0],\n",
       "     'n_samples': 1591,\n",
       "     'gain': 52.675236024571404,\n",
       "     'sl': {'y_pred': 27.886292834890966,\n",
       "      'level': 5,\n",
       "      'split': [2, 1.0],\n",
       "      'n_samples': 642,\n",
       "      'gain': 41.279988577842914,\n",
       "      'sl': {'y_pred': 24.29243353783231,\n",
       "       'level': 6,\n",
       "       'split': [0, 2.0],\n",
       "       'n_samples': 489,\n",
       "       'gain': 12.21741469949768,\n",
       "       'sl': {'y_pred': 27.83817427385892,\n",
       "        'level': 7,\n",
       "        'split': [1, 1.0],\n",
       "        'n_samples': 241,\n",
       "        'gain': 14.274135163726783,\n",
       "        'sl': {'y_pred': 25.15,\n",
       "         'level': 8,\n",
       "         'split': [3, 1.0],\n",
       "         'n_samples': 160,\n",
       "         'gain': 50.74683895921305,\n",
       "         'sl': {'y_pred': 17.936708860759495,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 79,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 32.18518518518518,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 81,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 33.148148148148145,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 81,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 20.846774193548388,\n",
       "        'level': 7,\n",
       "        'split': [3, 1.0],\n",
       "        'n_samples': 248,\n",
       "        'gain': 13.441752680902596,\n",
       "        'sl': {'y_pred': 18.293413173652695,\n",
       "         'level': 8,\n",
       "         'split': [1, 1.0],\n",
       "         'n_samples': 167,\n",
       "         'gain': 19.003215318690593,\n",
       "         'sl': {'y_pred': 14.011764705882353,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 85,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 22.73170731707317,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 82,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 26.11111111111111,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 81,\n",
       "         'gain': 0}}},\n",
       "      'sr': {'y_pred': 39.372549019607845,\n",
       "       'level': 6,\n",
       "       'split': [0, 2.0],\n",
       "       'n_samples': 153,\n",
       "       'gain': 51.00114262798752,\n",
       "       'sl': {'y_pred': 46.467532467532465,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 77,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 32.18421052631579,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 76,\n",
       "        'gain': 0}}},\n",
       "     'sr': {'y_pred': 13.0927291886196,\n",
       "      'level': 5,\n",
       "      'split': [0, 5.0],\n",
       "      'n_samples': 949,\n",
       "      'gain': 30.565333827750194,\n",
       "      'sl': {'y_pred': 9.130781499202552,\n",
       "       'level': 6,\n",
       "       'split': [0, 4.0],\n",
       "       'n_samples': 627,\n",
       "       'gain': 6.98994092013092,\n",
       "       'sl': {'y_pred': 11.821428571428571,\n",
       "        'level': 7,\n",
       "        'split': [2, 0.2727272727272805],\n",
       "        'n_samples': 308,\n",
       "        'gain': 3.9609375000001137,\n",
       "        'sl': {'y_pred': 10.602678571428571,\n",
       "         'level': 8,\n",
       "         'split': [1, 1.0],\n",
       "         'n_samples': 224,\n",
       "         'gain': 0.9298946496213318,\n",
       "         'sl': {'y_pred': 9.904761904761905,\n",
       "          'level': 9,\n",
       "          'split': [3, 1.0],\n",
       "          'n_samples': 147,\n",
       "          'gain': 2.485524154440924,\n",
       "          'sl': {'y_pred': 8.109375,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 64,\n",
       "           'gain': 0},\n",
       "          'sr': {'y_pred': 11.289156626506024,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 83,\n",
       "           'gain': 0}},\n",
       "         'sr': {'y_pred': 11.935064935064934,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 77,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 15.071428571428571,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 84,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 6.532915360501567,\n",
       "        'level': 7,\n",
       "        'split': [2, 1.0],\n",
       "        'n_samples': 319,\n",
       "        'gain': 0.88582189676276,\n",
       "        'sl': {'y_pred': 5.970212765957447,\n",
       "         'level': 8,\n",
       "         'split': [3, 1.0],\n",
       "         'n_samples': 235,\n",
       "         'gain': 1.3917864795533426,\n",
       "         'sl': {'y_pred': 5.1625,\n",
       "          'level': 9,\n",
       "          'split': [1, 1.0],\n",
       "          'n_samples': 160,\n",
       "          'gain': 2.048233474310802,\n",
       "          'sl': {'y_pred': 3.6578947368421053,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 76,\n",
       "           'gain': 0},\n",
       "          'sr': {'y_pred': 6.523809523809524,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 84,\n",
       "           'gain': 0}},\n",
       "         'sr': {'y_pred': 7.693333333333333,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 75,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 8.107142857142858,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 84,\n",
       "         'gain': 0}}},\n",
       "      'sr': {'y_pred': 20.80745341614907,\n",
       "       'level': 6,\n",
       "       'split': [2, 1.0],\n",
       "       'n_samples': 322,\n",
       "       'gain': 11.373055325092224,\n",
       "       'sl': {'y_pred': 18.820083682008367,\n",
       "        'level': 7,\n",
       "        'split': [3, 0.45454545454543904],\n",
       "        'n_samples': 239,\n",
       "        'gain': 14.550529981075215,\n",
       "        'sl': {'y_pred': 15.93421052631579,\n",
       "         'level': 8,\n",
       "         'split': [1, 1.0],\n",
       "         'n_samples': 152,\n",
       "         'gain': 33.561297087093536,\n",
       "         'sl': {'y_pred': 9.986486486486486,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 74,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 21.576923076923077,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 78,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 23.862068965517242,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 87,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 26.53012048192771,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 83,\n",
       "        'gain': 0}}}}},\n",
       "   'sr': {'y_pred': 78.059375,\n",
       "    'level': 3,\n",
       "    'split': [2, 1.0],\n",
       "    'n_samples': 320,\n",
       "    'gain': 162.939792765525,\n",
       "    'sl': {'y_pred': 70.75103734439834,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 241,\n",
       "     'gain': 104.86050200826321,\n",
       "     'sl': {'y_pred': 63.32911392405063,\n",
       "      'level': 5,\n",
       "      'split': [3, 1.0],\n",
       "      'n_samples': 158,\n",
       "      'gain': 378.58390343969404,\n",
       "      'sl': {'y_pred': 43.11842105263158,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 76,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 82.0609756097561,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 82,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 84.87951807228916,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 83,\n",
       "      'gain': 0}},\n",
       "    'sr': {'y_pred': 100.35443037974683,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 79,\n",
       "     'gain': 0}}},\n",
       "  'sr': {'y_pred': 212.8397435897436,\n",
       "   'level': 2,\n",
       "   'split': [2, 1.0],\n",
       "   'n_samples': 312,\n",
       "   'gain': 601.7174544483132,\n",
       "   'sl': {'y_pred': 198.91949152542372,\n",
       "    'level': 3,\n",
       "    'split': [3, 1.0],\n",
       "    'n_samples': 236,\n",
       "    'gain': 747.9490833767159,\n",
       "    'sl': {'y_pred': 177.63945578231292,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 147,\n",
       "     'gain': 2167.7832422517604,\n",
       "     'sl': {'y_pred': 133.24675324675326,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 77,\n",
       "      'gain': 0},\n",
       "     'sr': {'y_pred': 226.47142857142856,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 70,\n",
       "      'gain': 0}},\n",
       "    'sr': {'y_pred': 234.06741573033707,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 89,\n",
       "     'gain': 0}},\n",
       "   'sr': {'y_pred': 256.0657894736842,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 76,\n",
       "    'gain': 0}}},\n",
       " 'sr': {'y_pred': 260.15818540433924,\n",
       "  'level': 1,\n",
       "  'split': [0, 21.0],\n",
       "  'n_samples': 5070,\n",
       "  'gain': 3856.6410764702523,\n",
       "  'sl': {'y_pred': 289.9788834951456,\n",
       "   'level': 2,\n",
       "   'split': [0, 16.0],\n",
       "   'n_samples': 4120,\n",
       "   'gain': 2699.7602064102357,\n",
       "   'sl': {'y_pred': 248.42857142857142,\n",
       "    'level': 3,\n",
       "    'split': [0, 9.0],\n",
       "    'n_samples': 2513,\n",
       "    'gain': 2249.0939181242575,\n",
       "    'sl': {'y_pred': 374.1597444089457,\n",
       "     'level': 4,\n",
       "     'split': [3, 1.0],\n",
       "     'n_samples': 313,\n",
       "     'gain': 1667.3255068829094,\n",
       "     'sl': {'y_pred': 349.6304347826087,\n",
       "      'level': 5,\n",
       "      'split': [2, 1.0],\n",
       "      'n_samples': 230,\n",
       "      'gain': 1275.5540093280797,\n",
       "      'sl': {'y_pred': 324.04605263157896,\n",
       "       'level': 6,\n",
       "       'split': [1, 1.0],\n",
       "       'n_samples': 152,\n",
       "       'gain': 4753.571890319421,\n",
       "       'sl': {'y_pred': 254.18666666666667,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 75,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 392.09090909090907,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 77,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 399.4871794871795,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 78,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 442.13253012048193,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 83,\n",
       "      'gain': 0}},\n",
       "    'sr': {'y_pred': 230.54045454545454,\n",
       "     'level': 4,\n",
       "     'split': [0, 12.0],\n",
       "     'n_samples': 2200,\n",
       "     'gain': 659.195474312397,\n",
       "     'sl': {'y_pred': 201.03481012658227,\n",
       "      'level': 5,\n",
       "      'split': [2, 1.0],\n",
       "      'n_samples': 948,\n",
       "      'gain': 330.0783985209746,\n",
       "      'sl': {'y_pred': 190.60448807854138,\n",
       "       'level': 6,\n",
       "       'split': [1, 1.0],\n",
       "       'n_samples': 713,\n",
       "       'gain': 527.588456406309,\n",
       "       'sl': {'y_pred': 174.14012738853503,\n",
       "        'level': 7,\n",
       "        'split': [3, 1.0],\n",
       "        'n_samples': 471,\n",
       "        'gain': 2200.340452611341,\n",
       "        'sl': {'y_pred': 128.31535269709545,\n",
       "         'level': 8,\n",
       "         'split': [0, 10.0],\n",
       "         'n_samples': 241,\n",
       "         'gain': 419.51029849382303,\n",
       "         'sl': {'y_pred': 157.64556962025316,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 79,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 114.01234567901234,\n",
       "          'level': 9,\n",
       "          'split': [0, 11.0],\n",
       "          'n_samples': 162,\n",
       "          'gain': 152.7402872108314,\n",
       "          'sl': {'y_pred': 101.5,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 80,\n",
       "           'gain': 0},\n",
       "          'sr': {'y_pred': 126.21951219512195,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 82,\n",
       "           'gain': 0}}},\n",
       "        'sr': {'y_pred': 222.15652173913043,\n",
       "         'level': 8,\n",
       "         'split': [0, 10.0],\n",
       "         'n_samples': 230,\n",
       "         'gain': 223.755600157323,\n",
       "         'sl': {'y_pred': 242.44444444444446,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 81,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 211.1275167785235,\n",
       "          'level': 9,\n",
       "          'split': [0, 11.0],\n",
       "          'n_samples': 149,\n",
       "          'gain': 475.1934673857195,\n",
       "          'sl': {'y_pred': 189.76315789473685,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 76,\n",
       "           'gain': 0},\n",
       "          'sr': {'y_pred': 233.36986301369862,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 73,\n",
       "           'gain': 0}}}},\n",
       "       'sr': {'y_pred': 222.6487603305785,\n",
       "        'level': 7,\n",
       "        'split': [0, 11.0],\n",
       "        'n_samples': 242,\n",
       "        'gain': 154.40430488666425,\n",
       "        'sl': {'y_pred': 214.07926829268294,\n",
       "         'level': 8,\n",
       "         'split': [0, 10.0],\n",
       "         'n_samples': 164,\n",
       "         'gain': 466.1912923854834,\n",
       "         'sl': {'y_pred': 235.67073170731706,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 82,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 192.4878048780488,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 82,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 240.66666666666666,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 78,\n",
       "         'gain': 0}}},\n",
       "      'sr': {'y_pred': 232.68085106382978,\n",
       "       'level': 6,\n",
       "       'split': [0, 10.0],\n",
       "       'n_samples': 235,\n",
       "       'gain': 79.53369005582681,\n",
       "       'sl': {'y_pred': 245.70666666666668,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 75,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 226.575,\n",
       "        'level': 7,\n",
       "        'split': [0, 11.0],\n",
       "        'n_samples': 160,\n",
       "        'gain': 254.6716253516188,\n",
       "        'sl': {'y_pred': 210.8148148148148,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 81,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 242.73417721518987,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 79,\n",
       "         'gain': 0}}}},\n",
       "     'sr': {'y_pred': 252.8817891373802,\n",
       "      'level': 5,\n",
       "      'split': [2, 1.0],\n",
       "      'n_samples': 1252,\n",
       "      'gain': 739.6101221305798,\n",
       "      'sl': {'y_pred': 236.97963558413718,\n",
       "       'level': 6,\n",
       "       'split': [1, 1.0],\n",
       "       'n_samples': 933,\n",
       "       'gain': 941.9393726562012,\n",
       "       'sl': {'y_pred': 215.22544283413848,\n",
       "        'level': 7,\n",
       "        'split': [3, 1.0],\n",
       "        'n_samples': 621,\n",
       "        'gain': 3593.669878296889,\n",
       "        'sl': {'y_pred': 154.00986842105263,\n",
       "         'level': 8,\n",
       "         'split': [0, 13.0],\n",
       "         'n_samples': 304,\n",
       "         'gain': 28.538693356686053,\n",
       "         'sl': {'y_pred': 144.5068493150685,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 73,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 157.01298701298703,\n",
       "          'level': 9,\n",
       "          'split': [0, 14.0],\n",
       "          'n_samples': 231,\n",
       "          'gain': 15.58557115324038,\n",
       "          'sl': {'y_pred': 162.70666666666668,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 75,\n",
       "           'gain': 0},\n",
       "          'sr': {'y_pred': 154.27564102564102,\n",
       "           'level': 10,\n",
       "           'split': [0, 15.0],\n",
       "           'n_samples': 156,\n",
       "           'gain': 7.351286982244346,\n",
       "           'sl': {'y_pred': 157.09333333333333,\n",
       "            'level': 11,\n",
       "            'split': -1,\n",
       "            'n_samples': 75,\n",
       "            'gain': 0},\n",
       "           'sr': {'y_pred': 151.66666666666666,\n",
       "            'level': 11,\n",
       "            'split': -1,\n",
       "            'n_samples': 81,\n",
       "            'gain': 0}}}},\n",
       "        'sr': {'y_pred': 273.9305993690852,\n",
       "         'level': 8,\n",
       "         'split': [0, 13.0],\n",
       "         'n_samples': 317,\n",
       "         'gain': 14.238996299984137,\n",
       "         'sl': {'y_pred': 280.16470588235296,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 85,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 271.6465517241379,\n",
       "          'level': 9,\n",
       "          'split': [0, 15.0],\n",
       "          'n_samples': 232,\n",
       "          'gain': 7.07810652414264,\n",
       "          'sl': {'y_pred': 273.43125,\n",
       "           'level': 10,\n",
       "           'split': [0, 14.0],\n",
       "           'n_samples': 160,\n",
       "           'gain': 1.3858512973311008,\n",
       "           'sl': {'y_pred': 274.5232558139535,\n",
       "            'level': 11,\n",
       "            'split': -1,\n",
       "            'n_samples': 86,\n",
       "            'gain': 0},\n",
       "           'sr': {'y_pred': 272.1621621621622,\n",
       "            'level': 11,\n",
       "            'split': -1,\n",
       "            'n_samples': 74,\n",
       "            'gain': 0}},\n",
       "          'sr': {'y_pred': 267.68055555555554,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 72,\n",
       "           'gain': 0}}}},\n",
       "       'sr': {'y_pred': 280.27884615384613,\n",
       "        'level': 7,\n",
       "        'split': [0, 15.0],\n",
       "        'n_samples': 312,\n",
       "        'gain': 152.60303132398985,\n",
       "        'sl': {'y_pred': 272.780701754386,\n",
       "         'level': 8,\n",
       "         'split': [0, 13.0],\n",
       "         'n_samples': 228,\n",
       "         'gain': 7.356935225929192,\n",
       "         'sl': {'y_pred': 268.9066666666667,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 75,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 274.67973856209153,\n",
       "          'level': 9,\n",
       "          'split': [0, 14.0],\n",
       "          'n_samples': 153,\n",
       "          'gain': 29.544483600748208,\n",
       "          'sl': {'y_pred': 280.36986301369865,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 73,\n",
       "           'gain': 0},\n",
       "          'sr': {'y_pred': 269.4875,\n",
       "           'level': 10,\n",
       "           'split': -1,\n",
       "           'n_samples': 80,\n",
       "           'gain': 0}}},\n",
       "        'sr': {'y_pred': 300.6309523809524,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 84,\n",
       "         'gain': 0}}},\n",
       "      'sr': {'y_pred': 299.3918495297806,\n",
       "       'level': 6,\n",
       "       'split': [0, 14.0],\n",
       "       'n_samples': 319,\n",
       "       'gain': 72.91183119350899,\n",
       "       'sl': {'y_pred': 308.3421052631579,\n",
       "        'level': 7,\n",
       "        'split': [0, 13.0],\n",
       "        'n_samples': 152,\n",
       "        'gain': 7.258424469644524,\n",
       "        'sl': {'y_pred': 305.71794871794873,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 78,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 311.1081081081081,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 74,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 291.2455089820359,\n",
       "        'level': 7,\n",
       "        'split': [0, 15.0],\n",
       "        'n_samples': 167,\n",
       "        'gain': 5.079929857503885,\n",
       "        'sl': {'y_pred': 293.5679012345679,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 81,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 289.0581395348837,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 86,\n",
       "         'gain': 0}}}}}},\n",
       "   'sr': {'y_pred': 354.95457373988796,\n",
       "    'level': 3,\n",
       "    'split': [0, 19.0],\n",
       "    'n_samples': 1607,\n",
       "    'gain': 3943.2544173875212,\n",
       "    'sl': {'y_pred': 404.6589068825911,\n",
       "     'level': 4,\n",
       "     'split': [0, 17.0],\n",
       "     'n_samples': 988,\n",
       "     'gain': 3944.8672393296874,\n",
       "     'sl': {'y_pred': 313.9125,\n",
       "      'level': 5,\n",
       "      'split': [2, 1.0],\n",
       "      'n_samples': 320,\n",
       "      'gain': 1147.0627761839423,\n",
       "      'sl': {'y_pred': 295.82730923694777,\n",
       "       'level': 6,\n",
       "       'split': [1, 1.0],\n",
       "       'n_samples': 249,\n",
       "       'gain': 2137.3294051294542,\n",
       "       'sl': {'y_pred': 264.31176470588235,\n",
       "        'level': 7,\n",
       "        'split': [3, 1.0],\n",
       "        'n_samples': 170,\n",
       "        'gain': 6921.608950576123,\n",
       "        'sl': {'y_pred': 180.13095238095238,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 84,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 346.5348837209302,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 86,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 363.6455696202532,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 79,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 377.3380281690141,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 71,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 448.13023952095807,\n",
       "      'level': 5,\n",
       "      'split': [2, 1.0],\n",
       "      'n_samples': 668,\n",
       "      'gain': 2758.3116460999663,\n",
       "      'sl': {'y_pred': 418.65551181102364,\n",
       "       'level': 6,\n",
       "       'split': [1, 1.0],\n",
       "       'n_samples': 508,\n",
       "       'gain': 6504.672088800646,\n",
       "       'sl': {'y_pred': 361.2047477744807,\n",
       "        'level': 7,\n",
       "        'split': [3, 1.0],\n",
       "        'n_samples': 337,\n",
       "        'gain': 8127.5787136709405,\n",
       "        'sl': {'y_pred': 270.2455089820359,\n",
       "         'level': 8,\n",
       "         'split': [0, 18.0],\n",
       "         'n_samples': 167,\n",
       "         'gain': 5.846599110129318,\n",
       "         'sl': {'y_pred': 272.7073170731707,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 82,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 267.8705882352941,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 85,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 450.55882352941177,\n",
       "         'level': 8,\n",
       "         'split': [0, 18.0],\n",
       "         'n_samples': 170,\n",
       "         'gain': 883.8829664812583,\n",
       "         'sl': {'y_pred': 478.92134831460675,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 89,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 419.39506172839504,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 81,\n",
       "          'gain': 0}}},\n",
       "       'sr': {'y_pred': 531.8771929824561,\n",
       "        'level': 7,\n",
       "        'split': [0, 18.0],\n",
       "        'n_samples': 171,\n",
       "        'gain': 429.8170850598617,\n",
       "        'sl': {'y_pred': 552.9761904761905,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 84,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 511.5057471264368,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 87,\n",
       "         'gain': 0}}},\n",
       "      'sr': {'y_pred': 541.7125,\n",
       "       'level': 6,\n",
       "       'split': [0, 18.0],\n",
       "       'n_samples': 160,\n",
       "       'gain': 25.295022321392025,\n",
       "       'sl': {'y_pred': 547.0,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 76,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 536.9285714285714,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 84,\n",
       "        'gain': 0}}}},\n",
       "    'sr': {'y_pred': 275.6203554119548,\n",
       "     'level': 4,\n",
       "     'split': [2, 1.0],\n",
       "     'n_samples': 619,\n",
       "     'gain': 2526.497535369246,\n",
       "     'sl': {'y_pred': 245.69365426695842,\n",
       "      'level': 5,\n",
       "      'split': [1, 1.0],\n",
       "      'n_samples': 457,\n",
       "      'gain': 2310.9186051156357,\n",
       "      'sl': {'y_pred': 211.75737704918032,\n",
       "       'level': 6,\n",
       "       'split': [3, 1.0],\n",
       "       'n_samples': 305,\n",
       "       'gain': 3181.2680614123256,\n",
       "       'sl': {'y_pred': 156.6346153846154,\n",
       "        'level': 7,\n",
       "        'split': [0, 20.0],\n",
       "        'n_samples': 156,\n",
       "        'gain': 1075.1758058237283,\n",
       "        'sl': {'y_pred': 190.27631578947367,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 76,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 124.675,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 80,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 269.4697986577181,\n",
       "        'level': 7,\n",
       "        'split': [0, 20.0],\n",
       "        'n_samples': 149,\n",
       "        'gain': 1749.2907027301499,\n",
       "        'sl': {'y_pred': 310.4605263157895,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 76,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 226.7945205479452,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 73,\n",
       "         'gain': 0}}},\n",
       "      'sr': {'y_pred': 313.7894736842105,\n",
       "       'level': 6,\n",
       "       'split': [0, 20.0],\n",
       "       'n_samples': 152,\n",
       "       'gain': 2527.578540398483,\n",
       "       'sl': {'y_pred': 365.4054054054054,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 74,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 264.8205128205128,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 78,\n",
       "        'gain': 0}}},\n",
       "     'sr': {'y_pred': 360.0432098765432,\n",
       "      'level': 5,\n",
       "      'split': [0, 20.0],\n",
       "      'n_samples': 162,\n",
       "      'gain': 2703.611791478983,\n",
       "      'sl': {'y_pred': 410.7710843373494,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 83,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 306.746835443038,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 79,\n",
       "       'gain': 0}}}}},\n",
       "  'sr': {'y_pred': 130.83052631578948,\n",
       "   'level': 2,\n",
       "   'split': [0, 23.0],\n",
       "   'n_samples': 950,\n",
       "   'gain': 859.3465561971252,\n",
       "   'sl': {'y_pred': 151.87081339712918,\n",
       "    'level': 3,\n",
       "    'split': [2, 1.0],\n",
       "    'n_samples': 627,\n",
       "    'gain': 1014.9966400612811,\n",
       "    'sl': {'y_pred': 133.45744680851064,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 470,\n",
       "     'gain': 869.9497458836177,\n",
       "     'sl': {'y_pred': 112.86708860759494,\n",
       "      'level': 5,\n",
       "      'split': [3, 1.0],\n",
       "      'n_samples': 316,\n",
       "      'gain': 926.4392783300241,\n",
       "      'sl': {'y_pred': 82.8125,\n",
       "       'level': 6,\n",
       "       'split': [0, 22.0],\n",
       "       'n_samples': 160,\n",
       "       'gain': 82.8656094946482,\n",
       "       'sl': {'y_pred': 91.80246913580247,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 81,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 73.59493670886076,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 79,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 143.69230769230768,\n",
       "       'level': 6,\n",
       "       'split': [0, 22.0],\n",
       "       'n_samples': 156,\n",
       "       'gain': 351.32448340516794,\n",
       "       'sl': {'y_pred': 161.7283950617284,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 81,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 124.21333333333334,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 75,\n",
       "        'gain': 0}}},\n",
       "     'sr': {'y_pred': 175.7077922077922,\n",
       "      'level': 5,\n",
       "      'split': [0, 22.0],\n",
       "      'n_samples': 154,\n",
       "      'gain': 612.3172623969767,\n",
       "      'sl': {'y_pred': 200.77631578947367,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 76,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 151.28205128205127,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 78,\n",
       "       'gain': 0}}},\n",
       "    'sr': {'y_pred': 206.9936305732484,\n",
       "     'level': 4,\n",
       "     'split': [0, 22.0],\n",
       "     'n_samples': 157,\n",
       "     'gain': 655.1035706604007,\n",
       "     'sl': {'y_pred': 235.8985507246377,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 69,\n",
       "      'gain': 0},\n",
       "     'sr': {'y_pred': 184.32954545454547,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 88,\n",
       "      'gain': 0}}},\n",
       "   'sr': {'y_pred': 89.9876160990712,\n",
       "    'level': 3,\n",
       "    'split': [2, 1.0],\n",
       "    'n_samples': 323,\n",
       "    'gain': 347.4088015522316,\n",
       "    'sl': {'y_pred': 78.84873949579831,\n",
       "     'level': 4,\n",
       "     'split': [1, 1.0],\n",
       "     'n_samples': 238,\n",
       "     'gain': 240.06547380016082,\n",
       "     'sl': {'y_pred': 67.61538461538461,\n",
       "      'level': 5,\n",
       "      'split': [3, 1.0],\n",
       "      'n_samples': 156,\n",
       "      'gain': 449.52224892925756,\n",
       "      'sl': {'y_pred': 46.68354430379747,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 79,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 89.0909090909091,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 77,\n",
       "       'gain': 0}},\n",
       "     'sr': {'y_pred': 100.21951219512195,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 82,\n",
       "      'gain': 0}},\n",
       "    'sr': {'y_pred': 121.17647058823529,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 85,\n",
       "     'gain': 0}}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=tree_grow(X_train, y_train, level=0, min_gain=min_gain, max_depth=12, num_pct=num_pct)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([242.73417722,  43.11842105, 419.39506173, ..., 180.13095238,\n",
       "       399.48717949,   3.65789474])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=tree_predict(X_test, tree)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  13776.897591163506\n"
     ]
    }
   ],
   "source": [
    "mse_treeM = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse_treeM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Árbol de decisión con librería\n",
    "En la celda 5 entrene un árbol de decisiones con la **librería sklearn**, usando las variables predictoras \"season\" y \"hour\" y calibre los parámetros que considere conveniente para obtener un mejor desempeño. Recuerde dividir los datos en conjuntos de entrenamiento y validación para esto. Comente el desempeño del modelo con alguna métrica de desempeño de modelos de regresión y compare desempeño con el modelo del punto 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best score:  0.6109301888824614\n",
      "Mean Squared Error:  13776.897591163506\n"
     ]
    }
   ],
   "source": [
    "# Celda 5\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "reg=DecisionTreeRegressor()\n",
    "\n",
    "# Parámetros\n",
    "param_grid = {'max_depth': [6, 12, 18, 24],\n",
    "              'min_samples_split': [2, 4, 6],\n",
    "              'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "# Búsqueda mejor modelo\n",
    "grid_search = GridSearchCV(estimator=reg, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Mejores parámetros\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Estimar el modelo\n",
    "best_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Predicción\n",
    "y_pred = best_regressor.predict(X_test)\n",
    "\n",
    "# Calcular MSE\n",
    "mse_tree = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B - Métodos de ensamblajes\n",
    "En esta parte del taller se usará el conjunto de datos de Popularidad de Noticias Online. El objetivo es predecir si la notica es popular o no, la popularidad está dada por la cantidad de reacciones en redes sociales. Para más detalles puede visitar el siguiente enlace: [datos](https://archive.ics.uci.edu/ml/datasets/online+news+popularity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos popularidad de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.844262        5.0             1.0       1.0  ...   \n",
       "1                  0.815789        9.0             4.0       1.0  ...   \n",
       "2                  0.775701        4.0             3.0       1.0  ...   \n",
       "3                  0.677350       10.0             3.0       1.0  ...   \n",
       "4                  0.830357        3.0             2.0       1.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/mashable.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición variable de interes y variables predictoras\n",
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de la muestra en set de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - Árbol de decisión y regresión logística\n",
    "En la celda 6 construya un árbol de decisión y una regresión logística. Para el árbol calibre al menos un parámetro y evalúe el desempeño de cada modelo usando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best score:  0.6057777777777777\n",
      "Accuracy Tree:  0.6253333333333333\n",
      "F1-Score Tree:  0.6223118279569892\n",
      "Accuracy LR:  0.614\n",
      "F1-Score LR:  0.6106254203093476\n"
     ]
    }
   ],
   "source": [
    "# Celda 6\n",
    "# Árbol de decisión\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {'max_depth': [6, 12, 18, 24],\n",
    "              'min_samples_split': [2, 4, 6],\n",
    "              'min_samples_leaf': [1, 2, 3]}\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "best_regressor = grid_search.best_estimator_\n",
    "y_pred = best_regressor.predict(X_test)\n",
    "accuracyclf = accuracy_score(y_test, y_pred)\n",
    "f1clf = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy Tree: \", accuracyclf)\n",
    "print(\"F1-Score Tree: \", f1clf)\n",
    "\n",
    "# Regresión logísitca\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "accuracylr = accuracy_score(y_test, y_pred)\n",
    "f1lr = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy LR: \", accuracylr)\n",
    "print(\"F1-Score LR: \", f1lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Votación Mayoritaria\n",
    "En la celda 7 elabore un esamble con la metodología de **Votación mayoritaria** compuesto por 300 muestras bagged donde:\n",
    "\n",
    "-las primeras 100 muestras vienen de árboles de decisión donde max_depth tome un valor de su elección\\\n",
    "-las segundas 100 muestras vienen de árboles de decisión donde min_samples_leaf tome un valor de su elección\\\n",
    "-las últimas 100 muestras vienen de regresiones logísticas\n",
    "\n",
    "Evalúe cada uno de los tres modelos de manera independiente utilizando las métricas de Accuracy y F1-Score, luego evalúe el ensamble de modelos y compare los resultados. \n",
    "\n",
    "Nota: \n",
    "\n",
    "Para este ensamble de 300 modelos, deben hacer votación mayoritaria. Esto lo pueden hacer de distintas maneras. La más \"fácil\" es haciendo la votación \"manualmente\", como se hace a partir del minuto 5:45 del video de Ejemplo práctico de emsablajes en Coursera. Digo que es la más fácil porque si hacen la votación mayoritaria sobre las 300 predicciones van a obtener lo que se espera.\n",
    "\n",
    "Otra opción es: para cada uno de los 3 tipos de modelos, entrenar un ensamble de 100 modelos cada uno. Predecir para cada uno de esos tres ensambles y luego predecir como un ensamble de los 3 ensambles. La cuestión es que la votación mayoritaria al usar los 3 ensambles no necesariamente va a generar el mismo resultado que si hacen la votación mayoritaria directamente sobre los 300 modelos. Entonces, para los que quieran hacer esto, deben hacer ese último cálculo con cuidado.\n",
    "\n",
    "Para los que quieran hacerlo como ensamble de ensambles, digo que se debe hacer el ensamble final con cuidado por lo siguiente. Supongamos que:\n",
    "\n",
    "* para los 100 árboles del primer tipo, la votación mayoritaria es: 55% de los modelos predicen que la clase de una observación es \"1\"\n",
    "* para los 100 árboles del segundo tipo, la votación mayoritaria es: 55% de los modelos predicen que la clase de una observación es \"1\"\n",
    "* para las 100 regresiones logísticas, la votación mayoritaria es: 10% de los modelos predicen que la clase de una observación es \"1\"\n",
    "\n",
    "Si se hace la votación mayoritaria de los 300 modelos, la predicción de esa observación debería ser: (100*55%+100*55%+100*10%)/300 = 40% de los modelos votan porque la predicción debería ser \"1\". Es decir, la predicción del ensamble es \"0\" (dado que menos del 50% de modelos predijo un 1).\n",
    "\n",
    "Sin embargo, si miramos cada ensamble por separado, el primer ensamble predice \"1\", el segundo ensamble predice \"1\" y el último ensamble predice \"0\". Si hago votación mayoritaria sobre esto, la predicción va a ser \"1\", lo cual es distinto a si se hace la votación mayoritaria sobre los 300 modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n",
    "# Creación de 300 muestras de bootstrap \n",
    "np.random.seed(123)\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 300\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = {}\n",
    "tree2 = {}\n",
    "lr = {}\n",
    "\n",
    "# DataFrame para guardar las predicciones de cada árbol\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# Entrenamiento de un árbol sobre cada muestra boostrap y predicción sobre los datos de test\n",
    "for i in range(0,100):\n",
    "    X_b = X_train.iloc[samples[i],]\n",
    "    y_b = y_train.iloc[samples[i],]\n",
    "    tree1[i]=DecisionTreeClassifier(max_depth=5)\n",
    "    tree1[i].fit(X_b, y_b)\n",
    "    y_pred.iloc[:,i] = tree1[i].predict(X_test)\n",
    "\n",
    "for i in range(101,200):\n",
    "    X_b = X_train.iloc[samples[i],]\n",
    "    y_b = y_train.iloc[samples[i],]\n",
    "    tree2[i]=DecisionTreeClassifier(min_samples_leaf=10)\n",
    "    tree2[i].fit(X_b, y_b)\n",
    "    y_pred.iloc[:,i] = tree2[i].predict(X_test)\n",
    "\n",
    "for i in range(201,300):\n",
    "    X_b = X_train.iloc[samples[i],]\n",
    "    y_b = y_train.iloc[samples[i],]\n",
    "    lr[i]=LogisticRegression()\n",
    "    lr[i].fit(X_b, y_b)\n",
    "    y_pred.iloc[:,i] = lr[i].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9    ... 290 291 292 293 294 295 296  \\\n",
       "1483   1   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   1   1   1   \n",
       "2185   1   1   0   1   1   1   1   1   1   0  ...   0   0   1   0   1   1   0   \n",
       "2520   1   1   1   0   1   1   1   1   1   1  ...   1   1   1   1   1   1   1   \n",
       "3721   1   1   1   0   1   1   0   1   1   1  ...   1   1   1   1   1   1   1   \n",
       "3727   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "     297 298 299  \n",
       "1483   1   1   1  \n",
       "2185   1   0   0  \n",
       "2520   1   1   1  \n",
       "3721   1   1   1  \n",
       "3727   0   0   0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=y_pred\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483    1\n",
       "2185    1\n",
       "2520    1\n",
       "3721    1\n",
       "3727    0\n",
       "       ..\n",
       "3077    0\n",
       "5166    0\n",
       "2227    1\n",
       "5684    0\n",
       "1937    0\n",
       "Name: 0, Length: 1500, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=y_pred.mode(axis=1)[0]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy VM:  0.6306666666666667\n",
      "F1-Score VM:  0.6246612466124661\n"
     ]
    }
   ],
   "source": [
    "accuracyvm = accuracy_score(y_pred, y_test)\n",
    "f1scorevm = f1_score(y_pred, y_test)\n",
    "\n",
    "print(\"Accuracy VM: \", accuracyvm)\n",
    "print(\"F1-Score VM: \", f1scorevm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Votación Ponderada\n",
    "En la celda 8 elabore un ensamble con la metodología de **Votación ponderada** compuesto por 300 muestras bagged para los mismos tres escenarios del punto 7. Evalúe los modelos utilizando las métricas de Accuracy y F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8\n",
    "samples_oob = []\n",
    "# Obtención de las observaciones fuera de la bolsa \"out-of-bag\" para cada muestra\n",
    "for sample in samples:\n",
    "    samples_oob.append(sorted(set(range(n_samples)) - set(sample)))\n",
    "\n",
    "errors = np.zeros(300)\n",
    "\n",
    "for i in range(0,100):\n",
    "    y_pred_ = tree1[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errors[i] = 1-accuracy_score(y_train.iloc[samples_oob[i]], y_pred_)\n",
    "    \n",
    "for i in range(101,200):\n",
    "    y_pred_ = tree2[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errors[i] = 1-accuracy_score(y_train.iloc[samples_oob[i]], y_pred_)\n",
    "    \n",
    "for i in range(201,300):\n",
    "    y_pred_ = lr[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errors[i] = 1-accuracy_score(y_train.iloc[samples_oob[i]], y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de los pesos alpha de cada modelo de acuerdo al error OOB\n",
    "alpha = errors / errors.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483    0.910668\n",
       "2185    0.676740\n",
       "2520    0.800330\n",
       "3721    0.855211\n",
       "3727    0.094325\n",
       "          ...   \n",
       "3077    0.302660\n",
       "5166    0.154670\n",
       "2227    0.723108\n",
       "5684    0.237653\n",
       "1937    0.096045\n",
       "Length: 1500, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ponderación de las predicciones con los pesos alpha\n",
    "weighted_sum_1 = ((results) * alpha).sum(axis=1)\n",
    "weighted_sum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy VP:  0.6326666666666667\n",
      "F1-Score VP:  0.6269465132024374\n"
     ]
    }
   ],
   "source": [
    "# Desempeño al hacer votación ponderada\n",
    "y_pred_vp = (weighted_sum_1 >= 0.5).astype(np.int)\n",
    "accuracyvp=accuracy_score(y_pred_vp, y_test)\n",
    "f1scorevp=f1_score(y_pred_vp, y_test)\n",
    "\n",
    "print(\"Accuracy VP: \", accuracyvp)\n",
    "print(\"F1-Score VP: \", f1scorevp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 9 - Comparación y análisis de resultados\n",
    "En la celda 9 comente sobre los resultados obtenidos con las metodologías usadas en los puntos 7 y 8, compare los resultados y enuncie posibles ventajas o desventajas de cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy VM:  0.6306666666666667\n",
      "F1-Score VM:  0.6246612466124661\n",
      "Accuracy VP:  0.6326666666666667\n",
      "F1-Score VP:  0.6269465132024374\n"
     ]
    }
   ],
   "source": [
    "# Celda 9\n",
    "\n",
    "print(\"Accuracy VM: \", accuracyvm)\n",
    "print(\"F1-Score VM: \", f1scorevm)\n",
    "\n",
    "print(\"Accuracy VP: \", accuracyvp)\n",
    "print(\"F1-Score VP: \", f1scorevp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
